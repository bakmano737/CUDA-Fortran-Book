! 
!     Copyright (c) 2017, NVIDIA CORPORATION.  All rights reserved.
!
! NVIDIA CORPORATION and its licensors retain all intellectual property
! and proprietary rights in and to this software, related documentation
! and any modifications thereto.
!
!
!    These example codes are a portion of the code samples from the companion
!    website to the book "CUDA Fortran for Scientists and Engineers":
!
! http://store.elsevier.com/product.jsp?isbn=9780124169708
!

! multi-GPU transpose using CUDA's peer-to-peer capability
!
! This code requires all visible devices have direct access 
! with each other.  Use CUDA_VISIBLE_DEVICES to enumerate a 
! list of devices that are P2P accessible with each other.  
! Run the p2pAccess to see which devices have direct access 
! with each other.

module transpose_m
  integer, parameter :: cudaTileDim = 32
  integer, parameter :: blockRows = 8
contains

  attributes(global) subroutine cudaTranspose( &
       odata, ldo, idata, ldi)
    implicit none
    real, intent(out) :: odata(ldo,*)
    real, intent(in) :: idata(ldi,*)
    integer, value, intent(in) :: ldo, ldi
    real, shared :: tile(cudaTileDim+1, cudaTileDim)
    integer :: x, y, j

    x = (blockIdx%x-1) * cudaTileDim + threadIdx%x
    y = (blockIdx%y-1) * cudaTileDim + threadIdx%y
    
    do j = 0, cudaTileDim-1, blockRows
       tile(threadIdx%x, threadIdx%y+j) = idata(x,y+j)
    end do
    
    call syncthreads()
    
    x = (blockIdx%y-1) * cudaTileDim + threadIdx%x
    y = (blockIdx%x-1) * cudaTileDim + threadIdx%y
    
    do j = 0, cudaTileDim-1, blockRows
       odata(x,y+j) = tile(threadIdx%y+j, threadIdx%x)          
    end do
  end subroutine cudaTranspose

end module transpose_m

!
! Main code
!

program transposeP2P
  use cudafor
  use transpose_m 
  use timing

  implicit none

  ! global array size
  integer, parameter :: nx = 1024, ny = 768

  ! toggle async 
  logical, parameter :: asyncVersion = .true.
  
  ! host arrays (global)
  real :: h_idata(nx,ny), h_tdata(ny,nx), gold(ny,nx)
  real (kind=8) :: timeStart, timeStop

  ! CUDA vars and device arrays
  type (dim3) :: dimGrid, dimBlock
  integer(kind=cuda_stream_kind), allocatable :: &
       streamID(:,:)  ! (device, stage)

  ! distributed arrays
  type deviceArray
     real, device, allocatable :: v(:,:)
  end type deviceArray

  type (deviceArray), allocatable :: &
       d_idata(:), d_tdata(:), d_rdata(:)  ! (0:nDevices-1)

  integer :: nDevices
  type (cudaDeviceProp) :: prop
  integer, allocatable :: devices(:)

  integer :: p2pTileDimX, p2pTileDimY
  integer :: i, j, nyl, jl, jg, p, access, istat
  integer :: xOffset, yOffset
  integer :: rDev, sDev, stage

  ! determine number of devices

  istat = cudaGetDeviceCount(nDevices)
  write(*,"('Number of CUDA-capable devices: ', i0,/)") &
       nDevices

  do i = 0, nDevices-1
     istat = cudaGetDeviceProperties(prop, i)
     write(*,"('  Device ', i0, ': ', a)") i, trim(prop%name)
  end do

  ! check to make sure all devices are P2P accessible with 
  ! each other and enable peer access, if not exit
  
  do j = 0, nDevices-1
     do i = j+1, nDevices-1
        istat = cudaDeviceCanAccessPeer(access, j, i)
        if (access /= 1) then 
           write(*,*) &
                'Not all devices are P2P accessible ', & 
                'with each other.'
           write(*,*) &
                'Use the p2pAccess code to determine ', &
                'a subset that can do P2P and set'
           write(*,*) &
                'the environment variable ', &
                'CUDA_VISIBLE_DEVICES accordingly'
           write(*,*) "Test Passed"
           stop
        end if
        istat = cudaSetDevice(j)
        istat = cudaDeviceEnablePeerAccess(i, 0)
        istat = cudaSetDevice(i)
        istat = cudaDeviceEnablePeerAccess(j, 0)
     end do
  end do

  ! determine partition sizes and check tile sizes

  if (mod(nx,nDevices) == 0 .and. mod(ny,nDevices) == 0) then
     p2pTileDimX = nx/nDevices
     p2pTileDimY = ny/nDevices
  else
     write(*,*) 'nx, ny must be multiples of nDevices'
     stop
  endif

  if (mod(p2pTileDimX, cudaTileDim) /= 0 .or. &
       mod(p2pTileDimY, cudaTileDim) /= 0) then
     write(*,*) 'p2pTileDim* must be multiples of cudaTileDim'
     stop
  end if
  
  if (mod(cudaTileDim, blockRows) /= 0) then
     write(*,*) 'cudaTileDim must be a multiple of blockRows'
     stop
  end if

  dimGrid = dim3(p2pTileDimX/cudaTileDim, &
       p2pTileDimY/cudaTileDim, 1)
  dimBlock = dim3(cudaTileDim, blockRows, 1)

  ! write parameters

  write(*,*)
  write(*,"(/,'Array size: ', i0,'x',i0,/)") nx, ny

  write(*,"('CUDA block size: ', i0,'x',i0, &
       ',  CUDA tile size: ', i0,'x',i0)") &
       cudaTileDim, blockRows, cudaTileDim, cudaTileDim
     
  write(*,"('dimGrid: ', i0,'x',i0,'x',i0, &
       ',   dimBlock: ', i0,'x',i0,'x',i0,/)") &
       dimGrid%x, dimGrid%y, dimGrid%z, &
       dimBlock%x, dimBlock%y, dimBlock%z
  
  write(*,"('nDevices: ', i0, ', Local input array size: ', &
       i0,'x',i0)") nDevices, nx, p2pTileDimY
  write(*,"('p2pTileDim: ', i0,'x',i0,/)") &
       p2pTileDimX, p2pTileDimY

  write(*,"('async mode: ', l,//)") asyncVersion

  ! allocate and initialize arrays

  call random_number(h_idata)
  gold = transpose(h_idata)

  ! A stream is associated with a device, 
  ! so first index of streamID is the device (0:nDevices-1) 
  ! and second is the stage, which also spans (0:nDevices-1)
  !
  ! The 0th stage corresponds to the local transpose (on 
  ! diagonal tiles), and 1:nDevices-1 are the stages with
  ! P2P communication 

  allocate(streamID(0:nDevices-1,0:nDevices-1))
  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     do stage = 0, nDevices-1
        istat = cudaStreamCreate(streamID(p,stage))
     enddo
  enddo

  ! device data allocation and initialization

  allocate(d_idata(0:nDevices-1),&
       d_tdata(0:nDevices-1), d_rdata(0:nDevices-1))
  
  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     allocate(d_idata(p)%v(nx,p2pTileDimY), &
          d_rdata(p)%v(nx,p2pTileDimY), &
          d_tdata(p)%v(ny,p2pTileDimX))

     yOffset = p*p2pTileDimY
     d_idata(p)%v(:,:) = h_idata(:, &
          yOffset+1:yOffset+p2pTileDimY)
     d_rdata(p)%v(:,:) = -1.0
     d_tdata(p)%v(:,:) = -1.0
  enddo

  ! ---------
  ! transpose
  ! ---------

  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     istat = cudaDeviceSynchronize()
  enddo
  timeStart = wallclock()

  ! Stage 0:
  ! transpose diagonal blocks (local data) before kicking off 
  ! transfers and transposes of other blocks

  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     if (asyncVersion) then
        call cudaTranspose &
             <<<dimGrid, dimBlock, 0, streamID(p,0)>>> &
             (d_tdata(p)%v(p*p2pTileDimY+1,1), ny, &
             d_idata(p)%v(p*p2pTileDimX+1,1), nx)
     else
        call cudaTranspose<<<dimGrid, dimBlock>>> &
             (d_tdata(p)%v(p*p2pTileDimY+1,1), ny, &
             d_idata(p)%v(p*p2pTileDimX+1,1), nx)
     endif
  enddo
  
  ! now send data to blocks to the right of diagonal 
  ! (using mod for wrapping) and transpose

  do stage = 1, nDevices-1    ! stages = offset diagonals
     do rDev = 0, nDevices-1  ! device that receives
        sDev = mod(stage+rDev, nDevices)  ! dev that sends

        if (asyncVersion) then
           istat = cudaSetDevice(rDev)
           istat = cudaMemcpy2DAsync( &
                d_rdata(rDev)%v(sDev*p2pTileDimX+1,1), nx, &
                d_idata(sDev)%v(rDev*p2pTileDimX+1,1), nx, &
                p2pTileDimX, p2pTileDimY, &
                stream=streamID(rDev,stage))
        else
           istat = cudaMemcpy2D( &
                d_rdata(rDev)%v(sDev*p2pTileDimX+1,1), nx, &
                d_idata(sDev)%v(rDev*p2pTileDimX+1,1), nx, &
                p2pTileDimX, p2pTileDimY)
        end if

        istat = cudaSetDevice(rDev)
        if (asyncVersion) then
           call cudaTranspose &
                <<<dimGrid, dimBlock, 0, &
                streamID(rDev,stage)>>>  &
                (d_tdata(rDev)%v(sDev*p2pTileDimY+1,1), ny, &
                d_rdata(rDev)%v(sDev*p2pTileDimX+1,1), nx)
        else
           call cudaTranspose<<<dimGrid, dimBlock>>> &
                (d_tdata(rDev)%v(sDev*p2pTileDimY+1,1), ny, &
                d_rdata(rDev)%v(sDev*p2pTileDimX+1,1), nx)
        endif
     enddo
  enddo

  ! wait for execution to complete and get wallclock
  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     istat = cudaDeviceSynchronize()
  enddo
  timeStop = wallclock()

  ! transfer results to host and check for errors

  do p = 0, nDevices-1
     xOffset = p*p2pTileDimX
     istat = cudaSetDevice(p)
     h_tdata(:, xOffset+1:xOffset+p2pTileDimX) = &
          d_tdata(p)%v(:,:)
  end do

  if (all(h_tdata == gold)) then 
     write(*,"(' *** Test Passed ***',/)")
     write(*,"('Bandwidth (GB/s): ', f7.2,/)") &
          2.*(nx*ny*4)/(1.0e+9*(timeStop-timeStart)) 
  else
     write(*,"(' *** Failed ***',/)")
  endif

  ! cleanup

  do p = 0, nDevices-1
     istat = cudaSetDevice(p)
     deallocate(d_idata(p)%v, d_tdata(p)%v, d_rdata(p)%v)
     do stage = 0, nDevices-1
        istat = cudaStreamDestroy(streamID(p,stage))
     enddo
  end do
  deallocate(d_idata, d_tdata, d_rdata)

end program transposeP2P
